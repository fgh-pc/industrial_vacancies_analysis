"""
–û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ú–ï–ù–ï–î–ñ–ï–† –ë–ê–ó–´ –î–ê–ù–ù–´–• –î–õ–Ø 500K+ –ü–†–û–ú–´–®–õ–ï–ù–ù–´–• –í–ê–ö–ê–ù–°–ò–ô
–£–ü–†–û–©–ï–ù–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø - –î–ê–ù–ù–´–ï –£–ñ–ï –ü–†–û–ú–´–®–õ–ï–ù–ù–´–ï
"""

import sqlite3
import os
import json
import pandas as pd
from typing import Dict, List, Optional, Any
import logging
from datetime import datetime
import hashlib
import time
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ classification_config
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
try:
    from classification_config import classify_industry_segment, classify_position_level
    USE_IMPORTED_CLASSIFIERS = True
except ImportError:
    USE_IMPORTED_CLASSIFIERS = False

class IndustrialDatabaseManager:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –ë–î –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å 500K+ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """
    
    def __init__(self, db_path: str = "industrial_vacancies.db"):
        self.db_path = db_path
        self.connection = None
        self.logger = self._setup_logger()
        self.batch_size = 1000  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏
        self.processed_vacancy_ids = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        
    def _setup_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
        logger = logging.getLogger('IndustrialDatabaseManager')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger

    def create_connection(self) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å SQLite —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        try:
            self.connection = sqlite3.connect(self.db_path)
            
            # –í–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            self.connection.execute("PRAGMA journal_mode = WAL")
            self.connection.execute("PRAGMA synchronous = NORMAL")
            self.connection.execute("PRAGMA cache_size = -64000")  # 64MB –∫—ç—à
            self.connection.execute("PRAGMA temp_store = MEMORY")
            self.connection.execute("PRAGMA mmap_size = 268435456")  # 256MB mmap
            self.connection.execute("PRAGMA optimize")
            
            self.connection.row_factory = sqlite3.Row
            self.logger.info(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö {self.db_path} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return True
            
        except sqlite3.Error as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def create_tables(self) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ SQL —Ñ–∞–π–ª–∞.
        """
        try:
            sql_file_path = 'data/sql/create_tables.sql'
            if not os.path.exists(sql_file_path):
                # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                self.logger.info("üìù –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã —Å –±–∞–∑–æ–≤—ã–º SQL...")
                return self._create_basic_tables()
                
            with open(sql_file_path, 'r', encoding='utf-8') as f:
                sql_script = f.read()
                
            cursor = self.connection.cursor()
            cursor.executescript(sql_script)
            self.connection.commit()
            
            self.logger.info("‚úÖ –¢–∞–±–ª–∏—Ü—ã —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü: {e}")
            # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã
            return self._create_basic_tables()

    def _create_basic_tables(self) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π SQL —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.
        """
        try:
            cursor = self.connection.cursor()
            
            # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤–∞–∫–∞–Ω—Å–∏–π
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS vacancies (
                    id INTEGER PRIMARY KEY,
                    hh_id TEXT UNIQUE,
                    name TEXT NOT NULL,
                    name_cleaned TEXT,
                    area TEXT,
                    area_id INTEGER,
                    region TEXT,
                    salary_from INTEGER,
                    salary_to INTEGER,
                    salary_currency TEXT,
                    salary_avg_rub INTEGER,
                    experience TEXT,
                    schedule TEXT,
                    employment TEXT,
                    employer_name TEXT,
                    employer_id TEXT,
                    employer_trusted INTEGER DEFAULT 0,
                    industry_segment TEXT,
                    position_level TEXT,
                    professional_roles TEXT,
                    industrial_keywords TEXT,
                    key_skills_json TEXT,
                    published_at TIMESTAMP,
                    created_at TIMESTAMP,
                    collected_at TIMESTAMP,
                    collection_method TEXT,
                    collection_source TEXT,
                    snippet_requirement TEXT,
                    snippet_responsibility TEXT,
                    has_salary INTEGER DEFAULT 0,
                    is_industrial INTEGER DEFAULT 1
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –Ω–∞–≤—ã–∫–æ–≤
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS skills (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    vacancy_id INTEGER,
                    skill_name TEXT,
                    skill_category TEXT,
                    frequency_rank INTEGER,
                    FOREIGN KEY (vacancy_id) REFERENCES vacancies (id)
                )
            """)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_vacancies_industrial ON vacancies(is_industrial)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_vacancies_region ON vacancies(region)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_vacancies_industry_segment ON vacancies(industry_segment)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_skills_vacancy_id ON skills(vacancy_id)")
            
            self.connection.commit()
            self.logger.info("‚úÖ –ë–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–∞–∑–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü: {e}")
            return False

    def _check_tables_exist(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='vacancies'")
            return cursor.fetchone() is not None
        except:
            return False

    def _is_true_industrial_vacancy(self, vacancy: Dict) -> bool:
        """
        –£–ü–†–û–©–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        –ü–æ—Å–∫–æ–ª—å–∫—É JSON —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è.
        """
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if not vacancy.get('id'):
            return False
            
        name = vacancy.get('name', '')
        if not name:
            return False
        
        # –í–ê–ñ–ù–û: –ü–æ—Å–∫–æ–ª—å–∫—É —Ñ–∞–π–ª —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏,
        # –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è —è–≤–Ω–æ –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö
        
        name_lower = name.lower()
        
        # –¢–æ–ª—å–∫–æ —è–≤–Ω–æ –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        strong_non_industrial = {
            '–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º', '—Ç–æ—Ä–≥–æ–≤—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å', '–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥',
            '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '—é—Ä–∏—Å—Ç', '–∞–¥–≤–æ–∫–∞—Ç', '–Ω–æ—Ç–∞—Ä–∏—É—Å',
            '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫', '–∞–π—Ç–∏',
            '—Å–µ–∫—Ä–µ—Ç–∞—Ä—å', '–æ—Ñ–∏—Å-–º–µ–Ω–µ–¥–∂–µ—Ä', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä',
            '–æ—Ñ–∏—Ü–∏–∞–Ω—Ç', '–ø–æ–≤–∞—Ä', '–±–∞—Ä–º–µ–Ω', '–±–∞—Ä–∏—Å—Ç–∞',
            '–≤–æ–¥–∏—Ç–µ–ª—å', '–∫—É—Ä—å–µ—Ä', '—ç–∫—Å–ø–µ–¥–∏—Ç–æ—Ä',
            '—É–±–æ—Ä—â–∏–∫', '—É–±–æ—Ä—â–∏—Ü–∞', '–∫–ª–∏–Ω–∏–Ω–≥',
            '–æ—Ö—Ä–∞–Ω–Ω–∏–∫', '—Å—Ç–æ—Ä–æ–∂', '–∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä',
            '–ø—Ä–æ–¥–∞–≤–µ—Ü', '–∫–∞—Å—Å–∏—Ä', '–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç',
            '–º–µ–¥—Å–µ—Å—Ç—Ä–∞', '–≤—Ä–∞—á', '—Ñ–µ–ª—å–¥—à–µ—Ä',
            '—É—á–∏—Ç–µ–ª—å', '–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '–≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å'
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ —è–≤–Ω–æ –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ
        for exclude_keyword in strong_non_industrial:
            if exclude_keyword in name_lower:
                return False
        
        # –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–º–∏
        # –ø–æ—Å–∫–æ–ª—å–∫—É –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω
        return True

    def load_industrial_data_from_json(self, json_file_path: str) -> int:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ FINAL_MERGED_INDUSTRIAL_VACANCIES.json –≤ –ë–î.
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.
        """
        try:
            self.logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {json_file_path}...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            if os.path.exists(json_file_path):
                file_size = os.path.getsize(json_file_path) / (1024 * 1024)  # MB
                self.logger.info(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.1f} MB")
            else:
                self.logger.error(f"‚ùå –§–∞–π–ª {json_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return 0
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            self.logger.info("üîÑ –ß—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞...")
            start_time = time.time()
            
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            load_time = time.time() - start_time
            self.logger.info(f"‚úÖ JSON –ø—Ä–æ—á–∏—Ç–∞–Ω –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
    
            if not isinstance(data, list):
                self.logger.error("‚ùå JSON —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π")
                return 0
            
            total_vacancies = len(data)
            self.logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {total_vacancies:,} –≤–∞–∫–∞–Ω—Å–∏–π –≤ —Ñ–∞–π–ª–µ")
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
            self._analyze_data_before_load(data)
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if not self._check_tables_exist():
                self.logger.info("üîÑ –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã...")
                if not self.create_tables():
                    self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã")
                    return 0
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏
            total_inserted = self.insert_vacancies_batch(data)
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≥—Ä—É–∑–∫–∏
            self._analyze_load_results(total_vacancies, total_inserted)
            
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_inserted:,} –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            
            # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
            self._create_additional_indexes()
            
            return total_inserted
            
        except KeyboardInterrupt:
            self.logger.info("‚èπÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return 0
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return 0

    def _analyze_data_before_load(self, data: List[Dict]):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."""
        try:
            self.logger.info("üîç –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ü–ï–†–ï–î –ó–ê–ì–†–£–ó–ö–û–ô:")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π
            sample_vacancy = data[0] if data else {}
            self.logger.info(f"  üìã –ü—Ä–∏–º–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–∏: ID={sample_vacancy.get('id')}, Name={sample_vacancy.get('name')[:50]}...")
            
            # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ vs –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
            industrial_count = 0
            non_industrial_count = 0
            has_salary_count = 0
            
            for i, vacancy in enumerate(data[:1000]):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é 1000 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                if self._is_true_industrial_vacancy(vacancy):
                    industrial_count += 1
                else:
                    non_industrial_count += 1
                
                if vacancy.get('salary'):
                    has_salary_count += 1
            
            self.logger.info(f"  üè≠ –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è): {industrial_count}/1000")
            self.logger.info(f"  üö´ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (—è–≤–Ω–æ –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ): {non_industrial_count}/1000")
            self.logger.info(f"  üí∞ –° –∑–∞—Ä–ø–ª–∞—Ç–æ–π (–≤—ã–±–æ—Ä–∫–∞): {has_salary_count}/1000")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å ID
            ids = [v.get('id') for v in data if v.get('id')]
            unique_ids = set(ids)
            self.logger.info(f"  üîë –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {len(unique_ids):,} –∏–∑ {len(ids):,}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

    def _analyze_load_results(self, total_vacancies: int, inserted_count: int):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏."""
        self.logger.info("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ó–ê–ì–†–£–ó–ö–ò:")
        self.logger.info(f"  üìÅ –í —Ñ–∞–π–ª–µ: {total_vacancies:,} –≤–∞–∫–∞–Ω—Å–∏–π")
        self.logger.info(f"  üíæ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {inserted_count:,} –≤–∞–∫–∞–Ω—Å–∏–π")
        
        if total_vacancies > 0:
            success_rate = (inserted_count / total_vacancies) * 100
            self.logger.info(f"  üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏: {success_rate:.1f}%")
            
            if success_rate < 80:
                self.logger.warning("  ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π:")
                self.logger.warning("    ‚Ä¢ –î—É–±–ª–∏–∫–∞—Ç—ã –≤–∞–∫–∞–Ω—Å–∏–π")
                self.logger.warning("    ‚Ä¢ –Ø–≤–Ω–æ –Ω–µ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã")
                self.logger.warning("    ‚Ä¢ –û—à–∏–±–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö")

    def insert_vacancies_batch(self, vacancies: List[Dict]) -> int:
        """
        –ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.
        """
        if not vacancies:
            self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏")
            return 0
            
        inserted_count = 0
        total_vacancies = len(vacancies)
        
        self.logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≤—Å—Ç–∞–≤–∫—É {total_vacancies:,} –≤–∞–∫–∞–Ω—Å–∏–π...")
        self.logger.info("üí° –ò–°–ü–û–õ–¨–ó–£–ï–ú –£–ü–†–û–©–ï–ù–ù–£–Æ –§–ò–õ–¨–¢–†–ê–¶–ò–Æ (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ)")
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö ID –¥–ª—è –Ω–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        self.processed_vacancy_ids.clear()
        
        try:
            cursor = self.connection.cursor()
            
            # –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤—Å—Ç–∞–≤–∫–∏
            cursor.execute("BEGIN TRANSACTION")
            
            for i, vacancy in enumerate(vacancies):
                try:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –±–µ–∑ ID
                    if not vacancy.get('id'):
                        continue
                    
                    # –£–ü–†–û–©–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
                    vacancy_id = self._generate_vacancy_id(vacancy)
                    if vacancy_id in self.processed_vacancy_ids:
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
                    if not self._is_true_industrial_vacancy(vacancy):
                        continue
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–º–∏)
                    vacancy_data = self._prepare_vacancy_data(vacancy)
                    
                    # –í—Å—Ç–∞–≤–ª—è–µ–º –≤–∞–∫–∞–Ω—Å–∏—é
                    cursor.execute("""
                        INSERT OR IGNORE INTO vacancies (
                            id, hh_id, name, name_cleaned, area, area_id, region,
                            salary_from, salary_to, salary_currency, salary_avg_rub,
                            experience, schedule, employment, employer_name, employer_id,
                            employer_trusted, industry_segment, position_level,
                            professional_roles, industrial_keywords, key_skills_json,
                            published_at, created_at, collected_at, collection_method,
                            snippet_requirement, snippet_responsibility, has_salary, is_industrial
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, vacancy_data)
                    
                    inserted_count += 1
                    self.processed_vacancy_ids.add(vacancy_id)
                    
                    # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞–≤—ã–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                    if vacancy.get('key_skills'):
                        self._insert_skills_batch(cursor, vacancy_data[0], vacancy['key_skills'])
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5000 –≤–∞–∫–∞–Ω—Å–∏–π
                    if inserted_count % 5000 == 0:
                        progress = (inserted_count / total_vacancies) * 100
                        self.logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {inserted_count:,}/{total_vacancies:,} ({progress:.1f}%)")
                        
                    # –ö–æ–º–º–∏—Ç–∏–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    if inserted_count % self.batch_size == 0:
                        self.connection.commit()
                        cursor.execute("BEGIN TRANSACTION")
                        
                except sqlite3.IntegrityError:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                except Exception as e:
                    if inserted_count % 1000 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –Ω–µ –≤—Å–µ –æ—à–∏–±–∫–∏
                        self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy.get('id')}: {e}")
                    continue
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–º–º–∏—Ç
            self.connection.commit()
            self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–æ {inserted_count:,} –≤–∞–∫–∞–Ω—Å–∏–π")
            
        except Exception as e:
            self.connection.rollback()
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–µ: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            
        return inserted_count

    def insert_vacancy(self, vacancy: Dict) -> bool:
        """
        –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –≤—Å—Ç–∞–≤–∫–∞ –ø—Ä–æ—à–ª–∞ –±–µ–∑ –æ—à–∏–±–æ–∫.
        """
        try:
            return self.insert_vacancies_batch([vacancy]) > 0
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return False

    def _create_additional_indexes(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤."""
        try:
            cursor = self.connection.cursor()
            
            self.logger.info("üîß –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã...")
            
            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_vacancies_salary_avg ON vacancies(salary_avg_rub)",
                "CREATE INDEX IF NOT EXISTS idx_vacancies_published_at ON vacancies(published_at)",
                "CREATE INDEX IF NOT EXISTS idx_vacancies_position_level ON vacancies(position_level)",
                "CREATE INDEX IF NOT EXISTS idx_vacancies_employer ON vacancies(employer_name)",
                "CREATE INDEX IF NOT EXISTS idx_vacancies_experience ON vacancies(experience)",
                "CREATE INDEX IF NOT EXISTS idx_vacancies_has_salary ON vacancies(has_salary)",
                "CREATE INDEX IF NOT EXISTS idx_skills_skill_name ON skills(skill_name)",
                "CREATE INDEX IF NOT EXISTS idx_skills_category ON skills(skill_category)"
            ]
            
            for index_sql in indexes:
                cursor.execute(index_sql)
            
            self.connection.commit()
            self.logger.info("‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã: {e}")

    def _prepare_vacancy_data(self, vacancy: Dict) -> tuple:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ –ë–î.
        """
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        vacancy_id = self._generate_vacancy_id(vacancy)
        hh_id = vacancy.get('id', '')
        name = vacancy.get('name', '')
        name_cleaned = name.lower() if name else ''
        
        # –õ–æ–∫–∞—Ü–∏—è
        area_data = vacancy.get('area', {})
        area = area_data.get('name', '')
        area_id = area_data.get('id', 0)
        region = vacancy.get('region', '')
        
        # –ó–∞—Ä–ø–ª–∞—Ç–∞
        salary_data = vacancy.get('salary', {})
        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        salary_currency = salary_data.get('currency', '')
        salary_avg_rub = self._calculate_avg_salary_rub(salary_data)
        has_salary = 1 if salary_avg_rub else 0
        
        # –û–ø—ã—Ç –∏ –≥—Ä–∞—Ñ–∏–∫
        experience_data = vacancy.get('experience', {})
        experience = experience_data.get('name', '')
        
        schedule_data = vacancy.get('schedule', {})
        schedule = schedule_data.get('name', '')
        
        employment_data = vacancy.get('employment', {})
        employment = employment_data.get('name', '')
        
        # –†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å
        employer_data = vacancy.get('employer', {})
        employer_name = employer_data.get('name', '')
        employer_id = employer_data.get('id', '')
        employer_trusted = 1 if employer_data.get('trusted') else 0
        
        # –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        industry_segment = self._classify_industry_segment(vacancy)
        position_level = self._classify_position_level(vacancy)
        
        professional_roles = self._extract_professional_roles(vacancy)
        industrial_keywords = self._extract_industrial_keywords(vacancy)
        
        # –ù–∞–≤—ã–∫–∏
        key_skills = vacancy.get('key_skills', [])
        key_skills_json = json.dumps(key_skills, ensure_ascii=False) if key_skills else '[]'
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        published_at = self._parse_datetime(vacancy.get('published_at'))
        created_at = self._parse_datetime(vacancy.get('created_at'))
        collected_at = self._parse_datetime(vacancy.get('collected_at'))
        
        # –ú–µ—Ç–æ–¥ —Å–±–æ—Ä–∞
        collection_method = vacancy.get('collection_method', 'industrial_client')
        collection_source = 'FINAL_MERGED_INDUSTRIAL_VACANCIES'
        
        # –°–Ω–∏–ø–ø–µ—Ç—ã
        snippet_data = vacancy.get('snippet', {})
        snippet_requirement = snippet_data.get('requirement', '')
        snippet_responsibility = snippet_data.get('responsibility', '')
        
        # –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π —Ñ–ª–∞–≥ - –í–°–ï–ì–î–ê 1 (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ)
        is_industrial = 1
        
        return (
            vacancy_id, hh_id, name, name_cleaned, area, area_id, region,
            salary_from, salary_to, salary_currency, salary_avg_rub,
            experience, schedule, employment, employer_name, employer_id,
            employer_trusted, industry_segment, position_level,
            professional_roles, industrial_keywords, key_skills_json,
            published_at, created_at, collected_at, collection_method,
            snippet_requirement, snippet_responsibility, has_salary, is_industrial
        )

    def _generate_vacancy_id(self, vacancy: Dict) -> int:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–π ID –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏.
        """
        hh_id = vacancy.get('id', '')
        if hh_id and hh_id.isdigit():
            return int(hh_id)
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö—ç—à-based ID –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö ID
            return int(hashlib.md5(hh_id.encode()).hexdigest()[:8], 16)

    def _calculate_avg_salary_rub(self, salary_data: Dict) -> Optional[int]:
        """
        –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ —Ä—É–±–ª—è—Ö.
        """
        if not salary_data:
            return None
            
        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        currency = salary_data.get('currency', '').upper()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ä—É–±–ª–∏
        exchange_rates = {
            'RUR': 1.0, 'RUB': 1.0,
            'USD': 95.0, 'EUR': 100.0,
            'KZT': 0.2, 'BYR': 30.0
        }
        
        rate = exchange_rates.get(currency, 1.0)
        
        # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –∑–∞—Ä–ø–ª–∞—Ç—ã
        if salary_from and salary_to:
            avg_salary = (salary_from + salary_to) / 2
        elif salary_from:
            avg_salary = salary_from * 1.2  # +20% –¥–ª—è "–æ—Ç"
        elif salary_to:
            avg_salary = salary_to * 0.8    # -20% –¥–ª—è "–¥–æ"
        else:
            return None
            
        return int(avg_salary * rate)

    def _classify_industry_segment(self, vacancy: Dict) -> str:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç—Ä–∞—Å–ª–µ–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∏–∑ classification_config.py –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞.
        """
        if USE_IMPORTED_CLASSIFIERS:
            name = vacancy.get('name', '')
            employer_name = vacancy.get('employer', {}).get('name', '')
            return classify_industry_segment(name, employer_name)
        
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è
        name = vacancy.get('name', '').lower()
        employer_name = vacancy.get('employer', {}).get('name', '').lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        segments_keywords = {
            '–º–∞—à–∏–Ω–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ': [
                '–º–∞—à–∏–Ω–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ', '—Å—Ç–∞–Ω–∫–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ', '–∞–≤—Ç–æ–º–æ–±–∏–ª–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ',
                '–∞–≤–∏–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ', '—Å—É–¥–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ', '–æ–±–æ—Ä–æ–Ω–ø—Ä–æ–º', '–≤–∞–≥–æ–Ω–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ'
            ],
            '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è': [
                '–º–µ—Ç–∞–ª–ª—É—Ä–≥', '—Å—Ç–∞–ª–µ–≤–∞—Ä', '–ø—Ä–æ–∫–∞—Ç', '–ª–∏—Ç–µ–π—â', '–º–µ—Ç–∞–ª–ª–æ–æ–±—Ä–∞–±–æ—Ç–∫',
                '–∫–æ–≤–∫', '—à—Ç–∞–º–ø–æ–≤', '–ø—Ä–µ—Å—Å–æ–≤'
            ],
            '—Ö–∏–º–∏—á–µ—Å–∫–∞—è': [
                '—Ö–∏–º–∏–∫', '–ª–∞–±–æ—Ä–∞–Ω—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥ —Ö–∏–º–∏', '–Ω–µ—Ñ—Ç–µ—Ö–∏–º', '–ø–æ–ª–∏–º–µ—Ä',
                '–ø–ª–∞—Å—Ç–º–∞—Å—Å', '—Ä–µ–∑–∏–Ω–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫', '–ª–∞–∫–æ–∫—Ä–∞—Å–æ—á–Ω'
            ],
            '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': [
                '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫', '—ç–ª–µ–∫—Ç—Ä–∏–∫', '—ç–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–µ—Ä', '—ç–ª–µ–∫—Ç—Ä–æ–º–µ—Ö–∞–Ω–∏–∫',
                '—Ä–µ–ª–µ–π—â–∏–∫', '—ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫', '—Ç–µ–ø–ª–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫'
            ],
            '–Ω–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤–∞—è': [
                '–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '–±—É—Ä–æ–≤–∏–∫', '–Ω–µ—Ñ—Ç—è–Ω–∏–∫', '–≥–∞–∑–æ–≤–∏–∫', '–Ω–µ—Ñ—Ç–µ–¥–æ–±—ã—á–∞',
                '–Ω–µ—Ñ—Ç–µ–ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫', '—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥'
            ],
            '–≥–æ—Ä–Ω–æ–¥–æ–±—ã–≤–∞—é—â–∞—è': [
                '–≥–æ—Ä–Ω—è–∫', '–≤–∑—Ä—ã–≤–Ω–∏–∫', '–ø—Ä–æ—Ö–æ–¥—á–∏–∫', '–º–∞—Ä–∫—à–µ–π–¥–µ—Ä', '–æ–±–æ–≥–∞—Ç–∏—Ç–µ–ª—å',
                '—à–∞—Ö—Ç', '—Ä—É–¥–Ω–∏–∫', '–∫–∞—Ä—å–µ—Ä'
            ],
            '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è': [
                '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å', '–º–æ–Ω—Ç–∞–∂–Ω–∏–∫', '–∫–∞–º–µ–Ω—â–∏–∫', '—à—Ç—É–∫–∞—Ç—É—Ä', '–º–∞–ª—è—Ä',
                '–∫—Ä–æ–≤–µ–ª—å—â–∏–∫', '–∞—Ä–º–∞—Ç—É—Ä—â–∏–∫', '–±–µ—Ç–æ–Ω—â–∏–∫'
            ],
            '–ø—Ä–∏–±–æ—Ä–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ': [
                '–∫–∏–ø', '–∫–∏–ø–∏–∞', '–ø—Ä–∏–±–æ—Ä–∏—Å—Ç', '–∞—Å—É—Ç–ø', '–∞–≤—Ç–æ–º–∞—Ç–∏–∫–∞', '—Ç–µ–ª–µ–º–µ—Ö–∞–Ω–∏–∫',
                '—Ä–∞–¥–∏–æ—ç–ª–µ–∫—Ç—Ä–æ–Ω', '—ç–ª–µ–∫—Ç—Ä–æ–Ω—â–∏–∫'
            ],
            '–¥–µ—Ä–µ–≤–æ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∞—è': [
                '–¥–µ—Ä–µ–≤–æ–æ–±—Ä–∞–±–æ—Ç–∫', '—Å—Ç–æ–ª—è—Ä', '–ø–ª–æ—Ç–Ω–∏–∫', '–ª–µ—Å–Ω–∏–∫', '–ª–µ—Å–æ–∑–∞–≥–æ—Ç–æ–≤–∫',
                '–º–µ–±–µ–ª—å—â', '–ø–∞—Ä–∫–µ—Ç—á'
            ],
            '–ø–∏—â–µ–≤–∞—è': [
                '–ø–∏—â–µ–≤', '—Ç–µ—Ö–Ω–æ–ª–æ–≥ –ø–∏—â–µ–≤', '–∞–ø–ø–∞—Ä–∞—Ç—á–∏–∫ –ø–∏—â–µ–≤', '–æ–ø–µ—Ä–∞—Ç–æ—Ä –ª–∏–Ω–∏–∏',
                '–º—É–∫–æ–º–æ–ª', '–∫–æ–Ω–¥–∏—Ç–µ—Ä', '–º–∞—Å–ª–æ–¥–µ–ª', '—Å—ã—Ä–æ–¥–µ–ª'
            ]
        }
        
        for segment, keywords in segments_keywords.items():
            for keyword in keywords:
                if keyword in name or keyword in employer_name:
                    return segment
        
        return '–¥—Ä—É–≥–æ–µ'

    def _classify_position_level(self, vacancy: Dict) -> str:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è –ø–æ–∑–∏—Ü–∏–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∏–∑ classification_config.py –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞.
        """
        if USE_IMPORTED_CLASSIFIERS:
            name = vacancy.get('name', '')
            return classify_position_level(name)
        
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è
        name = vacancy.get('name', '').lower()
        
        levels_keywords = {
            '—Ä–∞–±–æ—á–∏–π': [
                '—Ä–∞–±–æ—á–∏–π', '–æ–ø–µ—Ä–∞—Ç–æ—Ä', '–≥—Ä—É–∑—á–∏–∫', '—Å–ª–µ—Å–∞—Ä—å', '—Ç–æ–∫–∞—Ä—å', '—Ñ—Ä–µ–∑–µ—Ä–æ–≤—â–∏–∫',
                '—Å–≤–∞—Ä—â–∏–∫', '–º–æ–Ω—Ç–∞–∂–Ω–∏–∫', '—ç–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–µ—Ä', '–Ω–∞–ª–∞–¥—á–∏–∫'
            ],
            '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç': [
                '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç', '—Ç–µ—Ö–Ω–æ–ª–æ–≥', '–º–∞—Å—Ç–µ—Ä', '–±—Ä–∏–≥–∞–¥–∏—Ä', '–º–µ—Ö–∞–Ω–∏–∫', '—ç–ª–µ–∫—Ç—Ä–∏–∫'
            ],
            '–∏–Ω–∂–µ–Ω–µ—Ä': [
                '–∏–Ω–∂–µ–Ω–µ—Ä', '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä', '–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫', '—Ç–µ—Ö–Ω–∏–∫'
            ],
            '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å': [
                '–Ω–∞—á–∞–ª—å–Ω–∏–∫', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', '–¥–∏—Ä–µ–∫—Ç–æ—Ä', '–∑–∞–º', '–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å',
                '—É–ø—Ä–∞–≤–ª—è—é—â', '–ø—Ä–æ—Ä–∞–±', '–º–∞—Å—Ç–µ—Ä —É—á–∞—Å—Ç–∫–∞'
            ],
            '–≤—ã—Å—à–µ–µ_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ': [
                '–≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π', '–¥–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä',
                '–≥–ª–∞–≤–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä', '–≥–ª–∞–≤–Ω—ã–π —Ç–µ—Ö–Ω–æ–ª–æ–≥'
            ]
        }
        
        for level, keywords in levels_keywords.items():
            for keyword in keywords:
                if keyword in name:
                    return level
        
        return '–¥—Ä—É–≥–æ–µ'

    def _extract_professional_roles(self, vacancy: Dict) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–æ–ª–∏.
        """
        roles = vacancy.get('professional_roles', [])
        if roles:
            role_names = [role.get('name', '') for role in roles if role.get('name')]
            return ', '.join(role_names)
        return ''

    def _extract_industrial_keywords(self, vacancy: Dict) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞.
        """
        name = vacancy.get('name', '').lower()
        snippet = vacancy.get('snippet', {}).get('requirement', '').lower()
        
        industrial_keywords = set()
        
        # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        keywords_list = [
            '–∏–Ω–∂–µ–Ω–µ—Ä', '—Ç–µ—Ö–Ω–æ–ª–æ–≥', '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä', '–º–µ—Ö–∞–Ω–∏–∫', '—ç–ª–µ–∫—Ç—Ä–∏–∫',
            '—Å–≤–∞—Ä—â–∏–∫', '—Ç–æ–∫–∞—Ä—å', '—Ñ—Ä–µ–∑–µ—Ä–æ–≤—â–∏–∫', '–Ω–∞–ª–∞–¥—á–∏–∫', '–æ–ø–µ—Ä–∞—Ç–æ—Ä',
            '–∞–ø–ø–∞—Ä–∞—Ç—á–∏–∫', '–º–∞—à–∏–Ω–∏—Å—Ç', '–º–æ–Ω—Ç–∞–∂–Ω–∏–∫', '—Ä–µ–º–æ–Ω—Ç–Ω–∏–∫', '—Å—Ç–∞–Ω–æ—á–Ω–∏–∫'
        ]
        
        for keyword in keywords_list:
            if keyword in name or keyword in snippet:
                industrial_keywords.add(keyword)
        
        return ', '.join(industrial_keywords)

    def _parse_datetime(self, date_str: str) -> Optional[str]:
        """
        –ü–∞—Ä—Å–∏—Ç datetime —Å—Ç—Ä–æ–∫—É.
        """
        if not date_str:
            return None
            
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
            formats = [
                "%Y-%m-%dT%H:%M:%S%z",
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d"
            ]
            
            for fmt in formats:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.isoformat()
                except ValueError:
                    continue
                    
            return None
        except:
            return None

    def _insert_skills_batch(self, cursor, vacancy_id: int, skills: List[Dict]):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–≤—ã–∫–∏ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏.
        """
        if not skills:
            return
            
        for i, skill in enumerate(skills):
            try:
                skill_name = skill.get('name', '')
                if not skill_name:
                    continue
                    
                skill_category = self._categorize_skill(skill_name)
                frequency_rank = i + 1
                
                cursor.execute("""
                    INSERT INTO skills (vacancy_id, skill_name, skill_category, frequency_rank)
                    VALUES (?, ?, ?, ?)
                """, (vacancy_id, skill_name, skill_category, frequency_rank))
                
            except Exception as e:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—à–∏–±–∫–∏ –Ω–∞–≤—ã–∫–æ–≤

    def _categorize_skill(self, skill_name: str) -> str:
        """
        –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤.
        """
        skill_lower = skill_name.lower()
        
        categories = {
            '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ': [
                'autocad', 'solidworks', '–∫–æ–º–ø–∞—Å', '—á–µ—Ä—á–µ–Ω–∏–µ', '—á—Ç–µ–Ω–∏–µ —á–µ—Ä—Ç–µ–∂–µ–π',
                '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ', '—Ä–µ–º–æ–Ω—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è', '–Ω–∞–ª–∞–¥–∫–∞'
            ],
            '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ': [
                '—Å–≤–∞—Ä–∫–∞', '—Ç–æ–∫–∞—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã', '—Ñ—Ä–µ–∑–µ—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã', '–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–ª–ª–æ–≤',
                '–ª–∏—Ç–µ–π–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ', '–ø—Ä–æ–∫–∞—Ç–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ'
            ],
            '–∫–∏–ø–∏–∞_–∞—Å—É_—Ç–ø': [
                '–∫–∏–ø', '–∫–∏–ø–∏–∞', '–∞—Å—É—Ç–ø', '—Ç–µ–ª–µ–º–µ—Ö–∞–Ω–∏–∫–∞', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è',
                '–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ-–∏–∑–º–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–±–æ—Ä—ã', '—Å—Ä–µ–¥—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏'
            ],
            '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ': [
                '—ç–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂', '—ç–ª–µ–∫—Ç—Ä–æ–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ', '—Ä–µ–ª–µ–π–Ω–∞—è –∑–∞—â–∏—Ç–∞',
                '—ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ', '—Å–∏–ª–æ–≤–∞—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞'
            ],
            '—Ö–∏–º–∏—á–µ—Å–∫–∏–µ': [
                '—Ö–∏–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑', '–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã',
                '–∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞', '–º–µ—Ç—Ä–æ–ª–æ–≥–∏—è'
            ],
            '—É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ': [
                '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º', '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞', '–∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞',
                '–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å', '–≤–µ–¥–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏'
            ],
            '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ': [
                '1—Å', 'ms office', 'excel', 'word', '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞',
                '–¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ', '—Ä–∞–±–æ—Ç–∞ —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö'
            ],
            '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': [
                '–æ—Ö—Ä–∞–Ω–∞ —Ç—Ä—É–¥–∞', '—Ç–µ—Ö–Ω–∏–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏', '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
                '–ø–æ–∂–∞—Ä–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '—ç–ª–µ–∫—Ç—Ä–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'
            ]
        }
        
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in skill_lower:
                    return category
        
        return '–¥—Ä—É–≥–∏–µ'

    def get_database_stats(self) -> Dict:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        """
        if not self.connection:
            return {}
            
        stats = {}
        cursor = self.connection.cursor()
        
        try:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("SELECT COUNT(*) as total FROM vacancies")
            stats['total_vacancies'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) as with_salary FROM vacancies WHERE has_salary = 1")
            stats['vacancies_with_salary'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT employer_name) as employers FROM vacancies")
            stats['unique_employers'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT region) as regions FROM vacancies")
            stats['unique_regions'] = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
            cursor.execute("""
                SELECT industry_segment, COUNT(*) as count 
                FROM vacancies 
                GROUP BY industry_segment 
                ORDER BY count DESC
            """)
            stats['industry_segments'] = dict(cursor.fetchall())
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
            cursor.execute("""
                SELECT position_level, COUNT(*) as count 
                FROM vacancies 
                GROUP BY position_level 
                ORDER BY count DESC
            """)
            stats['position_levels'] = dict(cursor.fetchall())
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞–≤—ã–∫–∞–º
            cursor.execute("SELECT COUNT(DISTINCT skill_name) as skills FROM skills")
            stats['unique_skills'] = cursor.fetchone()[0]
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            
        return stats

    def close_connection(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö."""
        if self.connection:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º
            try:
                self.connection.execute("PRAGMA optimize")
                self.connection.execute("VACUUM")
            except:
                pass
                
            self.connection.close()
            self.logger.info("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
def load_industrial_data():
    """
    –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ FINAL_MERGED_INDUSTRIAL_VACANCIES.json
    —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.
    """
    db_manager = IndustrialDatabaseManager()
    
    if db_manager.create_connection():
        # –ü—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ñ–∞–π–ª—É
        json_file = "data/FINAL_MERGED_INDUSTRIAL_VACANCIES.json"
        
        if os.path.exists(json_file):
            inserted = db_manager.load_industrial_data_from_json(json_file)
            
            if inserted > 0:
                stats = db_manager.get_database_stats()
                print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
                print(f"   –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {stats.get('total_vacancies', 0):,}")
                print(f"   –° –∑–∞—Ä–ø–ª–∞—Ç–æ–π: {stats.get('vacancies_with_salary', 0):,}")
                print(f"   –†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π: {stats.get('unique_employers', 0):,}")
                print(f"   –†–µ–≥–∏–æ–Ω–æ–≤: {stats.get('unique_regions', 0):,}")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {stats.get('unique_skills', 0):,}")
                
                print("\nüè≠ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –°–ï–ì–ú–ï–ù–¢–ê–ú:")
                for segment, count in list(stats.get('industry_segments', {}).items())[:5]:
                    print(f"   {segment}: {count:,}")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
                    
        else:
            print(f"‚ùå –§–∞–π–ª {json_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        db_manager.close_connection()
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")


if __name__ == "__main__":
    load_industrial_data()